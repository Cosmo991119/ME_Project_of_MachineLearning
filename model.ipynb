{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRHOHibon1yn"
      },
      "source": [
        "!pip install lingvo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0IJX6vhpGo5"
      },
      "source": [
        "import lingvo.compat as tf\n",
        "from lingvo.core import base_model\n",
        "from lingvo.core import insertion\n",
        "from lingvo.core import metrics\n",
        "from lingvo.core import py_utils\n",
        "from lingvo.core import tpu_embedding_layers\n",
        "from lingvo.tasks.mt import decoder\n",
        "from lingvo.tasks.mt import encoder\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqo3p7zp2Z7O"
      },
      "source": [
        "Transformer model\n",
        "\n",
        "参考了lingvo的mt模型框架\n",
        "\n",
        "@misc{shen2019lingvo,\n",
        "    title={Lingvo: a Modular and Scalable Framework for Sequence-to-Sequence Modeling},\n",
        "    author={Jonathan Shen and Patrick Nguyen and Yonghui Wu and Zhifeng Chen and others},\n",
        "    year={2019},\n",
        "    eprint={1902.08295},\n",
        "    archivePrefix={arXiv},\n",
        "    primaryClass={cs.LG}\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BC-SXvMA2aV6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "6cf486a3-9e54-4b35-fecd-31ff195caa2a"
      },
      "source": [
        "class TransformerModel(base_model.BaseTask):\n",
        "  \"\"\"Transformer Model.\n",
        "  Implements Attention is All You Need:\n",
        "  https://arxiv.org/abs/1706.03762\n",
        "  \"\"\"\n",
        "\n",
        "  @classmethod \n",
        "  def Params(cls):# return a default Params(base layer)\n",
        "    #tp = p.train ep = p.eval dp = p.decoder \n",
        "    p = super().Params()\n",
        "    p.encoder = encoder.TransformerEncoder.Params()#configure of transformer encoder\n",
        "    p.decoder = decoder.TransformerDecoder.Params()#same as encoder\n",
        "    return p\n",
        "\n",
        "  def __init__(self, params): #constructor\n",
        "    super().__init__(params)\n",
        "    p = self.params\n",
        "    assert p.encoder.model_dim == p.decoder.source_dim\n",
        "\n",
        "  \n",
        "  def _EncoderDevice(self):\n",
        "    \"\"\"Returns the device to run the encoder computation.\"\"\"\n",
        "    if self.params.device_mesh is not None:\n",
        "      # We perform spmd based partitioning, in which case, we don't specifically\n",
        "      # assign any operation to a particular device.\n",
        "      return tf.device('')\n",
        "    if py_utils.use_tpu():\n",
        "      return tf.device(self.cluster.WorkerDeviceInModelSplit(0))\n",
        "    else:\n",
        "      return tf.device('')\n",
        "\n",
        "  \n",
        "  def _DecoderDevice(self):\n",
        "    \"\"\"Returns the device to run the decoder computation.\"\"\"\n",
        "    if self.params.device_mesh is not None:\n",
        "      # We perform spmd based partitioning, in which case, we don't specifically\n",
        "      # assign any operation to a particular device.\n",
        "      return tf.device('')\n",
        "    if py_utils.use_tpu():\n",
        "      return tf.device(self.cluster.WorkerDeviceInModelSplit(1))\n",
        "    else:\n",
        "      return tf.device('')\n",
        "\n",
        "  #use tpu embedding\n",
        "  def _PropagateEmbeddingIds(self, input_batch):\n",
        "    \"\"\"Propagate the TPU embedding ids to the encoder/decoder input batch.\"\"\"\n",
        "    feature_names = (\n",
        "        tpu_embedding_layers.TpuEmbeddingCollection.Get().feature_names)\n",
        "    if feature_names:\n",
        "      batch = input_batch.DeepCopy()\n",
        "      for name in feature_names: \n",
        "        assert name in batch#recheck\n",
        "        assert name not in batch.src, f'Duplicate {name} in batch.src'\n",
        "        assert name not in batch.tgt, f'Duplicate {name} in batch.tgt'\n",
        "        batch.src[name] = batch[name]\n",
        "        batch.tgt[name] = batch[name]\n",
        "      return batch\n",
        "\n",
        "    return input_batch\n",
        "\n",
        "  #root layer of network\n",
        "  def ComputePredictions(self, theta, batch): #get the theta and input batch, return the network predictions\n",
        "    p = self.params\n",
        "    batch = self._PropagateEmbeddingIds(batch)\n",
        "\n",
        "    with self._EncoderDevice():\n",
        "      encoder_outputs = (\n",
        "          self.enc.FProp(theta.enc, batch.src) if p.encoder else None) # FProp method that implements forward propagation through the layer.\n",
        "    with self._DecoderDevice():\n",
        "      predictions = self.dec.ComputePredictions(theta.dec, encoder_outputs,\n",
        "                                                batch.tgt)\n",
        "      if isinstance(predictions, py_utils.NestedMap):\n",
        "        # Pass through encoder output as well for possible use as a FProp output\n",
        "        # for various meta-MT modeling approaches, such as MT quality estimation\n",
        "        # classification.\n",
        "        predictions['encoder_outputs'] = encoder_outputs\n",
        "      return predictions\n",
        "\n",
        "  def ComputeLoss(self, theta, predictions, input_batch)://reutrn loss,(dictionary of scalar metrics, )\n",
        "    with self._DecoderDevice():\n",
        "      return self.dec.ComputeLoss(theta.dec, predictions, input_batch.tgt)\n",
        "\n",
        "  def _GetTokenizerKeyToUse(self, key):\n",
        "    \"\"\"Returns a tokenizer key to use for the provided `key`.\"\"\"\n",
        "    if key in self.input_generator.tokenizer_dict:\n",
        "      return key\n",
        "    return None\n",
        "\n",
        "\n",
        "\n",
        "  def _BeamSearchDecode(self, input_batch):\n",
        "    p = self.params\n",
        "    with tf.name_scope('fprop'), tf.name_scope(p.name):\n",
        "      encoder_outputs = self.enc.FPropDefaultTheta(input_batch.src)\n",
        "      encoder_outputs = self.dec.AddExtraDecodingInfo(encoder_outputs,\n",
        "                                                      input_batch.tgt)\n",
        "      decoder_outs = self.dec.BeamSearchDecode(encoder_outputs)\n",
        "\n",
        "      topk_hyps = decoder_outs.topk_hyps\n",
        "      topk_ids = decoder_outs.topk_ids\n",
        "      topk_lens = decoder_outs.topk_lens\n",
        "      topk_scores = decoder_outs.topk_scores\n",
        "\n",
        "      slen = tf.cast(\n",
        "          tf.round(tf.reduce_sum(1 - input_batch.src.paddings, 1) - 1),\n",
        "          tf.int32)\n",
        "      srcs = self.input_generator.IdsToStrings(\n",
        "          input_batch.src.ids, slen, self._GetTokenizerKeyToUse('src'))\n",
        "      topk_decoded = self.input_generator.IdsToStrings(\n",
        "          topk_ids, topk_lens - 1, self._GetTokenizerKeyToUse('tgt'))\n",
        "      topk_decoded = tf.reshape(topk_decoded, tf.shape(topk_hyps))\n",
        "      topk_scores = tf.reshape(topk_scores, tf.shape(topk_hyps))\n",
        "\n",
        "      refs = self.input_generator.IdsToStrings(\n",
        "          input_batch.tgt.labels,\n",
        "          tf.cast(\n",
        "              tf.round(tf.reduce_sum(1.0 - input_batch.tgt.paddings, 1) - 1.0),\n",
        "              tf.int32), self._GetTokenizerKeyToUse('tgt'))\n",
        "\n",
        "      ret_dict = {\n",
        "          'target_ids': input_batch.tgt.ids,\n",
        "          'target_labels': input_batch.tgt.labels,\n",
        "          'target_weights': input_batch.tgt.weights,\n",
        "          'target_paddings': input_batch.tgt.paddings,\n",
        "          'sources': srcs,\n",
        "          'targets': refs,\n",
        "          'topk_decoded': topk_decoded,\n",
        "          'topk_lens': topk_lens,\n",
        "          'topk_scores': topk_scores,\n",
        "      }\n",
        "      return ret_dict\n",
        "\n",
        "  def _PostProcessBeamSearchDecodeOut(self, dec_out_dict, dec_metrics_dict):\n",
        "    \"\"\"Post processes the output from `_BeamSearchDecode`.\"\"\"\n",
        "    p = self.params\n",
        "    topk_scores = dec_out_dict['topk_scores']\n",
        "    topk_decoded = dec_out_dict['topk_decoded']\n",
        "    targets = dec_out_dict['targets']\n",
        "    sources = dec_out_dict['sources']\n",
        "    unsegment = dec_metrics_dict['corpus_bleu'].unsegmenter\n",
        "\n",
        "    num_samples = len(targets)\n",
        "    assert num_samples == len(topk_decoded), (\n",
        "        '%s vs %s' % (num_samples, len(topk_decoded)))\n",
        "    assert num_samples == len(sources)\n",
        "    dec_metrics_dict['num_samples_in_batch'].Update(num_samples)\n",
        "\n",
        "    key_value_pairs = []\n",
        "    for i in range(num_samples):\n",
        "      src, tgt = sources[i], targets[i]\n",
        "      src_unseg, tgt_unseg = unsegment(src), unsegment(tgt)\n",
        "      tf.logging.info('source: %s', src_unseg)\n",
        "      tf.logging.info('target: %s', tgt_unseg)\n",
        "      hyps = topk_decoded[i]\n",
        "      assert p.decoder.beam_search.num_hyps_per_beam == len(hyps)\n",
        "      info_str = u'src: {} tgt: {} '.format(src_unseg, tgt_unseg)\n",
        "      for n, (score, hyp_str) in enumerate(zip(topk_scores[i], hyps)):\n",
        "        hyp_str_unseg = unsegment(hyp_str)\n",
        "        tf.logging.info('  %f: %s', score, hyp_str_unseg)\n",
        "        info_str += u' hyp{n}: {hyp} score{n}: {score}'.format(\n",
        "            n=n, hyp=hyp_str_unseg, score=score)\n",
        "        # Only aggregate scores of the top hypothesis.\n",
        "        if n == 0:\n",
        "          dec_metrics_dict['corpus_bleu'].Update(tgt, hyp_str)\n",
        "      key_value_pairs.append((src_unseg, info_str))\n",
        "    return key_value_pairs\n",
        "\n",
        "  def CreateDecoderMetrics(self):\n",
        "    decoder_metrics = {\n",
        "        'num_samples_in_batch': metrics.AverageMetric(),\n",
        "        'corpus_bleu': metrics.CorpusBleuMetric(separator_type='wpm'),\n",
        "    }\n",
        "    return decoder_metrics\n",
        "\n",
        "  # optional decoder\n",
        "  def Decode(self, input_batch):\n",
        "    \"\"\"Constructs the decoding graph.\"\"\"\n",
        "    input_batch = self._PropagateEmbeddingIds(input_batch)\n",
        "    return self._BeamSearchDecode(input_batch)\n",
        "\n",
        "  def PostProcessDecodeOut(self, dec_out, dec_metrics):\n",
        "    return self._PostProcessBeamSearchDecodeOut(dec_out, dec_metrics)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-26751f87b9f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mMTBaseModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBaseTask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0;34m\"\"\"Base Class for NMT models.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_EncoderDevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;34m\"\"\"Returns the device to run the encoder computation.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'base_model' is not defined"
          ]
        }
      ]
    }
  ]
}